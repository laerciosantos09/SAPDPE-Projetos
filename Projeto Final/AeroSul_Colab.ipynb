{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header-1"
   },
   "source": [
    "# üöÄ SISTEMA INTELIGENTE AEROSUL - Google Colab\n",
    "## An√°lise de Sentimentos e Detec√ß√£o de Crises\n",
    "\n",
    "**Status:** ‚úÖ Pronto para usar\n",
    "\n",
    "Este notebook executa o sistema inteligente AeroSul no Google Colab.\n",
    "\n",
    "### Como usar:\n",
    "1. Clique em **Runtime** ‚Üí **Run all** (ou Ctrl+F9)\n",
    "2. Se quiser analisar um arquivo pr√≥prio, fa√ßa upload quando solicitado\n",
    "3. Se n√£o quiser, o sistema roda com dados de demonstra√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-setup"
   },
   "source": [
    "## üì¶ Passo 1: Instalar Depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Instalar depend√™ncias\n",
    "!pip install -q pandas numpy scikit-learn matplotlib seaborn openpyxl requests schedule\n",
    "\n",
    "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-core-system"
   },
   "source": [
    "## üîß Passo 2: Definir Classes do Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aerosul-system-core"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class TextCleaner:\n    \"\"\"Respons√°vel pela limpeza e normaliza√ß√£o de textos.\"\"\"\n    \n    @staticmethod\n    def clean_english(text: str) -> str:\n        \"\"\"Limpa textos em ingl√™s.\"\"\"\n        text = str(text).lower()\n        text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n        text = re.sub(r'http\\S+', '', text)\n        text = re.sub(r'[^a-z0-9\\s]', '', text)\n        return text.strip()\n    \n    @staticmethod\n    def clean_portuguese(text: str) -> str:\n        \"\"\"Limpa textos em portugu√™s.\"\"\"\n        text = str(text).lower()\n        text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n        text = re.sub(r'http\\S+', '', text)\n        text = re.sub(r'[^a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß√±0-9\\s]', '', text)\n        return text.strip()\n\n\nclass SentimentModel:\n    \"\"\"Modelo especializado em classifica√ß√£o de sentimentos.\"\"\"\n    \n    def __init__(self, language: str = 'english'):\n        self.language = language\n        self.pipeline = Pipeline([\n            ('tfidf', TfidfVectorizer(max_features=3000, stop_words=language)),\n            ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n        ])\n        self.is_trained = False\n        self.classes_ = None\n        self.metrics = {}\n    \n    def train(self, X_train, y_train, X_val=None, y_val=None):\n        \"\"\"Treina o modelo de sentimento.\"\"\"\n        print(f\"[SentimentModel] Treinando com {len(X_train)} amostras...\")\n        self.pipeline.fit(X_train, y_train)\n        self.is_trained = True\n        self.classes_ = self.pipeline.named_steps['clf'].classes_\n        \n        if X_val is not None and y_val is not None:\n            y_pred = self.pipeline.predict(X_val)\n            self.metrics['accuracy'] = accuracy_score(y_val, y_pred)\n            print(f\"[SentimentModel] Accuracy na Valida√ß√£o: {self.metrics['accuracy']:.4f}\")\n        \n        return self\n    \n    def predict(self, X) -> np.ndarray:\n        \"\"\"Prediz sentimentos.\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Modelo n√£o foi treinado.\")\n        return self.pipeline.predict(X)\n    \n    def predict_proba(self, X) -> np.ndarray:\n        \"\"\"Retorna probabilidades.\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Modelo n√£o foi treinado.\")\n        return self.pipeline.predict_proba(X)\n\n\nclass ReasonModel:\n    \"\"\"Modelo especializado em classifica√ß√£o de motivos.\"\"\"\n    \n    def __init__(self, language: str = 'english'):\n        self.language = language\n        self.pipeline = Pipeline([\n            ('tfidf', TfidfVectorizer(max_features=3000, stop_words=language)),\n            ('clf', LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=1000))\n        ])\n        self.is_trained = False\n        self.classes_ = None\n        self.metrics = {}\n    \n    def train(self, X_train, y_train, X_val=None, y_val=None):\n        \"\"\"Treina o modelo de motivos.\"\"\"\n        print(f\"[ReasonModel] Treinando com {len(X_train)} amostras...\")\n        self.pipeline.fit(X_train, y_train)\n        self.is_trained = True\n        self.classes_ = self.pipeline.named_steps['clf'].classes_\n        \n        if X_val is not None and y_val is not None:\n            y_pred = self.pipeline.predict(X_val)\n            self.metrics['accuracy'] = accuracy_score(y_val, y_pred)\n            print(f\"[ReasonModel] Accuracy na Valida√ß√£o: {self.metrics['accuracy']:.4f}\")\n        \n        return self\n    \n    def predict(self, X) -> np.ndarray:\n        \"\"\"Prediz motivos.\"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Modelo n√£o foi treinado.\")\n        return self.pipeline.predict(X)\n\n\nclass CrisisDetector:\n    \"\"\"Detecta padr√µes de crise.\"\"\"\n    \n    def __init__(self, threshold_multiplier: float = 1.5):\n        self.threshold_multiplier = threshold_multiplier\n        self.mean_negative = None\n        self.std_negative = None\n        self.crisis_threshold = None\n    \n    def fit(self, daily_negative_counts: pd.Series):\n        \"\"\"Calibra os limiares.\"\"\"\n        self.mean_negative = daily_negative_counts.mean()\n        self.std_negative = daily_negative_counts.std()\n        self.crisis_threshold = self.mean_negative + (self.threshold_multiplier * self.std_negative)\n        print(f\"[CrisisDetector] Limiar de crise calibrado: {self.crisis_threshold:.2f}\")\n        return self\n    \n    def detect(self, daily_counts: pd.Series) -> Dict:\n        \"\"\"Detecta crises.\"\"\"\n        if self.crisis_threshold is None:\n            raise ValueError(\"CrisisDetector n√£o foi calibrado.\")\n        \n        crisis_days = daily_counts[daily_counts > self.crisis_threshold]\n        \n        return {\n            'is_crisis': len(crisis_days) > 0,\n            'crisis_dates': crisis_days.index.tolist(),\n            'max_count': daily_counts.max(),\n            'max_date': daily_counts.idxmax(),\n            'normal_mean': self.mean_negative,\n            'threshold': self.crisis_threshold,\n            'severity_factor': daily_counts.max() / self.mean_negative if self.mean_negative > 0 else 0\n        }\n\n\nclass FinancialAnalyzer:\n    \"\"\"Calcula impacto financeiro.\"\"\"\n    \n    COST_TABLE = {\n        \"Lost Luggage\": 3000,\n        \"Late Flight\": 2500,\n        \"Cancelled Flight\": 5000,\n        \"Customer Service Issue\": 1500,\n        \"Bad Flight\": 1000,\n        \"Flight Attendant Complaints\": 1000,\n        \"longlines\": 500,\n        \"Damaged Luggage\": 800,\n        \"Flight Booking Problems\": 600,\n        \"Neutral Interaction\": 0,\n        \"Unclassified Negative\": 200,\n    }\n    \n    def __init__(self, exchange_rate: float = 6.00):\n        self.exchange_rate = exchange_rate\n    \n    def get_cost(self, reason: str) -> float:\n        \"\"\"Retorna custo para um motivo.\"\"\"\n        return self.COST_TABLE.get(reason, 200)\n    \n    def calculate_impact(self, df: pd.DataFrame, reason_column: str = 'IA_Motivo') -> Dict:\n        \"\"\"Calcula impacto financeiro.\"\"\"\n        df_negative = df[df.get('IA_Sentimento', 'unknown') == 'negative'].copy()\n        \n        if len(df_negative) == 0:\n            return {\n                'total_incidents': 0,\n                'total_usd': 0,\n                'total_brl': 0,\n                'by_reason': {}\n            }\n        \n        df_negative['cost_usd'] = df_negative[reason_column].apply(self.get_cost)\n        df_negative['cost_brl'] = df_negative['cost_usd'] * self.exchange_rate\n        \n        return {\n            'total_incidents': len(df_negative),\n            'total_usd': df_negative['cost_usd'].sum(),\n            'total_brl': df_negative['cost_brl'].sum(),\n            'by_reason': df_negative.groupby(reason_column)['cost_usd'].sum().to_dict()\n        }\n\n\nclass ActionRecommender:\n    \"\"\"Recomenda a√ß√µes.\"\"\"\n    \n    ACTION_MAP = {\n        ('negative', 'Lost Luggage'): \"üî¥ URGENTE: Rastrear bagagem, contatar cliente em 30 min\",\n        ('negative', 'Late Flight'): \"üü† MODERADO: Oferecer voucher de hotel/refei√ß√£o\",\n        ('negative', 'Cancelled Flight'): \"üî¥ URGENTE: Reacomodar em voo pr√≥ximo + compensa√ß√£o\",\n        ('negative', 'Customer Service Issue'): \"üü† MODERADO: Escalar para supervisor, investigar falha\",\n        ('negative', 'Bad Flight'): \"üü° BAIXO: Responder gentilmente, oferecer desconto pr√≥xima compra\",\n        ('neutral', None): \"üëç ENGAJAMENTO: Responder positivamente, solicitar feedback\",\n        ('positive', None): \"üíö FIDELIZA√á√ÉO: Like/Share, agradecer publicamente\",\n    }\n    \n    @staticmethod\n    def recommend(sentiment: str, reason: Optional[str] = None) -> str:\n        \"\"\"Retorna a√ß√£o recomendada.\"\"\"\n        key = (sentiment, reason)\n        if key in ActionRecommender.ACTION_MAP:\n            return ActionRecommender.ACTION_MAP[key]\n        \n        if sentiment == 'negative':\n            return f\"üü† INVESTIGAR: {reason or 'Motivo desconhecido'}\"\n        return \"‚û°Ô∏è SEM A√á√ÉO ESPEC√çFICA\"\n\n\nclass AeroSulSystem:\n    \"\"\"Orquestrador principal do sistema.\"\"\"\n    \n    def __init__(self, language: str = 'english'):\n        self.language = language\n        self.text_cleaner = TextCleaner()\n        self.sentiment_model = SentimentModel(language=language)\n        self.reason_model = ReasonModel(language=language)\n        self.crisis_detector = CrisisDetector()\n        self.financial_analyzer = FinancialAnalyzer()\n        self.action_recommender = ActionRecommender()\n        self.state = {\n            'models_trained': False,\n            'crisis_detector_calibrated': False,\n            'last_execution': None\n        }\n    \n    def train_from_data(self, df: pd.DataFrame, test_size: float = 0.2):\n        \"\"\"Treina os modelos a partir de um DataFrame.\"\"\"\n        print(\"\\n\" + \"=\"*70)\n        print(\"TREINANDO MODELOS\")\n        print(\"=\"*70)\n        \n        # Limpeza\n        print(f\"\\n[Etapa 1] Limpando textos...\")\n        cleaner_func = self.text_cleaner.clean_english if self.language == 'english' else self.text_cleaner.clean_portuguese\n        df['clean_text'] = df['text'].apply(cleaner_func)\n        print(f\"‚úì Textos normalizados\")\n        \n        # Modelo de Sentimento\n        print(f\"\\n[Etapa 2] Treinando Modelo de Sentimentos\")\n        df_sent = df[df['airline_sentiment'].isin(['negative', 'neutral', 'positive'])].copy()\n        X_train_s, X_val_s, y_train_s, y_val_s = train_test_split(\n            df_sent['clean_text'], df_sent['airline_sentiment'], \n            test_size=test_size, random_state=42\n        )\n        self.sentiment_model.train(X_train_s, y_train_s, X_val_s, y_val_s)\n        print(f\"‚úì Modelo de Sentimentos Treinado\")\n        \n        # Modelo de Motivos\n        print(f\"\\n[Etapa 3] Treinando Modelo de Motivos (Causas)\")\n        df_reason = df[(df['airline_sentiment'] == 'negative') & (df['negativereason'].notna())].copy()\n        if len(df_reason) > 0:\n            X_train_r, X_val_r, y_train_r, y_val_r = train_test_split(\n                df_reason['clean_text'], df_reason['negativereason'],\n                test_size=test_size, random_state=42\n            )\n            self.reason_model.train(X_train_r, y_train_r, X_val_r, y_val_r)\n            print(f\"‚úì Modelo de Motivos Treinado\")\n        else:\n            print(f\"‚ö† Sem dados negativos com motivos classificados\")\n        \n        # Calibra detector de crise\n        print(f\"\\n[Etapa 4] Calibrando Detector de Crises\")\n        if 'date' in df.columns or 'tweet_created' in df.columns:\n            date_col = 'tweet_created' if 'tweet_created' in df.columns else 'date'\n            df['date'] = pd.to_datetime(df[date_col])\n            daily_negatives = df[df['airline_sentiment'] == 'negative'].groupby(df['date'].dt.date).size()\n            self.crisis_detector.fit(daily_negatives)\n        else:\n            print(f\"‚ö† Sem coluna de data para calibra√ß√£o de crises\")\n        \n        self.state['models_trained'] = True\n        self.state['crisis_detector_calibrated'] = True\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"‚úì TREINAMENTO CONCLU√çDO COM SUCESSO\")\n        print(\"=\"*70)\n    \n    def analyze_data(self, df: pd.DataFrame, text_column: str = 'text', language: str = None) -> pd.DataFrame:\n        \"\"\"Analisa um DataFrame com textos.\"\"\"\n        if not self.state['models_trained']:\n            raise ValueError(\"Modelos n√£o foram treinados.\")\n        \n        lang = language or self.language\n        cleaner_func = self.text_cleaner.clean_english if lang == 'english' else self.text_cleaner.clean_portuguese\n        df['clean_text'] = df[text_column].apply(cleaner_func)\n        \n        # Predi√ß√µes\n        df['IA_Sentimento'] = self.sentiment_model.predict(df['clean_text'])\n        \n        # Motivos apenas para negativos\n        df['IA_Motivo'] = 'N/A'\n        mask_neg = df['IA_Sentimento'] == 'negative'\n        if mask_neg.sum() > 0 and self.reason_model.is_trained:\n            df.loc[mask_neg, 'IA_Motivo'] = self.reason_model.predict(df.loc[mask_neg, 'clean_text'])\n        \n        # Recomenda√ß√µes\n        df['Acao_Recomendada'] = df.apply(\n            lambda row: self.action_recommender.recommend(row['IA_Sentimento'], row['IA_Motivo']),\n            axis=1\n        )\n        \n        return df\n    \n    def detect_crisis(self, df: pd.DataFrame, date_column: str = 'tweet_created') -> Dict:\n        \"\"\"Detecta crises no per√≠odo.\"\"\"\n        if not self.state['crisis_detector_calibrated']:\n            return {'is_crisis': False, 'message': 'Detector n√£o calibrado'}\n        \n        if date_column not in df.columns:\n            return {'is_crisis': False, 'message': f'Coluna {date_column} n√£o encontrada'}\n        \n        df['date'] = pd.to_datetime(df[date_column]).dt.date\n        daily_negatives = df[df['IA_Sentimento'] == 'negative'].groupby('date').size()\n        \n        return self.crisis_detector.detect(daily_negatives)\n    \n    def get_financial_impact(self, df: pd.DataFrame) -> Dict:\n        \"\"\"Retorna an√°lise financeira.\"\"\"\n        return self.financial_analyzer.calculate_impact(df)\n\n\nprint(\"‚úÖ Classes do sistema carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-utils"
   },
   "source": [
    "## üéØ Passo 3: Fun√ß√µes Utilit√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utility-functions"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "def criar_dados_treino_simulados(n_samples: int = 500) -> pd.DataFrame:\n    \"\"\"Cria dados simulados para treinamento.\"\"\"\n    np.random.seed(42)\n    \n    sentimentos = ['negative', 'positive', 'neutral']\n    motivos = [\n        'Lost Luggage', 'Late Flight', 'Cancelled Flight',\n        'Customer Service Issue', 'Bad Flight'\n    ]\n    \n    textos_negat = [\n        \"lost my luggage in miami\",\n        \"flight delayed 4 hours very upset\",\n        \"cancelled my flight with no explanation\",\n        \"worst customer service ever\",\n        \"flight was terrible very uncomfortable\",\n        \"baggage was damaged\",\n        \"long lines at check in\",\n        \"booking problems with website\",\n        \"flight attendant was rude\",\n        \"terrible food on flight\",\n    ]\n    \n    textos_posit = [\n        \"amazing flight experience will fly again\",\n        \"great service and friendly crew\",\n        \"excellent cabin crew very professional\",\n        \"love flying with this airline\",\n        \"best flight ever so comfortable\",\n        \"fantastic experience incredible crew\",\n        \"wonderful service thank you\",\n        \"beautiful aircraft very clean\",\n    ]\n    \n    textos_neut = [\n        \"flight was on time\",\n        \"normal experience nothing special\",\n        \"average service\",\n        \"flight departed on schedule\",\n        \"check in was quick\",\n        \"boarding process smooth\",\n    ]\n    \n    data = []\n    for i in range(n_samples):\n        sentimento = np.random.choice(sentimentos, p=[0.45, 0.35, 0.20])\n        \n        if sentimento == 'negative':\n            texto = np.random.choice(textos_negat)\n            motivo = np.random.choice(motivos)\n        elif sentimento == 'positive':\n            texto = np.random.choice(textos_posit)\n            motivo = np.nan\n        else:\n            texto = np.random.choice(textos_neut)\n            motivo = np.nan\n        \n        data.append({\n            'text': texto,\n            'airline_sentiment': sentimento,\n            'negativereason': motivo if sentimento == 'negative' else np.nan,\n            'negativereason_gold': motivo if sentimento == 'negative' else np.nan,\n        })\n    \n    return pd.DataFrame(data)\n\n\ndef upload_arquivo(pasta_destino='./dados'):\n    \"\"\"\n    Permite upload de arquivo.\n    Retorna (arquivo_path, True) se arquivo foi feito upload\n    Retorna (None, False) se usu√°rio cancelou\n    \"\"\"\n    os.makedirs(pasta_destino, exist_ok=True)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"üìÇ UPLOAD DE ARQUIVO\")\n    print(\"=\"*70)\n    print(\"\\nVoc√™ pode fazer upload de um arquivo para an√°lise\")\n    print(\"Formatos aceitos: .xlsx, .xls, .csv\")\n    print(\"\\nOu deixe em branco para usar dados de demonstra√ß√£o\")\n    \n    try:\n        print(\"\\nüëá Clique em 'Selecionar arquivo' para fazer upload:\")\n        uploaded = files.upload()\n        \n        if len(uploaded) == 0:\n            print(\"\\n‚ö†Ô∏è  Nenhum arquivo foi selecionado\")\n            return None, False\n        \n        # Pegar primeiro arquivo\n        nome_arquivo = list(uploaded.keys())[0]\n        caminho_arquivo = os.path.join(pasta_destino, nome_arquivo)\n        \n        # Salvar arquivo\n        with open(caminho_arquivo, 'wb') as f:\n            f.write(uploaded[nome_arquivo])\n        \n        print(f\"\\n‚úÖ Arquivo '{nome_arquivo}' salvo com sucesso!\")\n        return caminho_arquivo, True\n    \n    except Exception as e:\n        print(f\"\\n‚ùå Erro ao fazer upload: {e}\")\n        return None, False\n\n\nprint(\"‚úÖ Fun√ß√µes utilit√°rias carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-main-execution"
   },
   "source": [
    "## üöÄ Passo 4: EXECU√á√ÉO PRINCIPAL\n",
    "\n",
    "### Escolha uma op√ß√£o:\n",
    "- **Op√ß√£o 1:** Usar dados de demonstra√ß√£o (r√°pido, ~2 min)\n",
    "- **Op√ß√£o 2:** Fazer upload de arquivo pr√≥prio (Excel/CSV)\n",
    "\n",
    "Execute a c√©lula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main-execution"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SELECIONAR MODO DE EXECU√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ SISTEMA INTELIGENTE AEROSUL - Google Colab\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Tentar fazer upload de arquivo\n",
    "arquivo_uploaded, arquivo_feito = upload_arquivo()\n",
    "\n",
    "# Decidir qual dataset usar\n",
    "if arquivo_feito and arquivo_uploaded:\n    print(f\"\\n‚úÖ Usando arquivo do upload: {arquivo_uploaded}\")\n",
    "    try:\n",
    "        # Detectar formato\n",
    "        if arquivo_uploaded.endswith('.xlsx') or arquivo_uploaded.endswith('.xls'):\n",
    "            df_treino = pd.read_excel(arquivo_uploaded)\n        else:\n",
    "            df_treino = pd.read_csv(arquivo_uploaded)\n",
    "        \n",
    "        print(f\"‚úì {len(df_treino)} registros carregados\")\n",
    "        print(f\"Colunas: {list(df_treino.columns)}\")\n",
    "        idioma_deteccao = 'portuguese' if any('√£' in str(col).lower() for col in df_treino.columns) else 'english'\n    except Exception as e:\n        print(f\"‚ùå Erro ao carregar arquivo: {e}\")\n        print(f\"\\n‚ö†Ô∏è  Usando dados de demonstra√ß√£o em vez disso...\")\n        df_treino = criar_dados_treino_simulados(300)\n        idioma_deteccao = 'english'\nelse:\n    print(f\"\\n‚ö†Ô∏è  Usando dados de demonstra√ß√£o (simulados)\")\n    df_treino = criar_dados_treino_simulados(300)\n    idioma_deteccao = 'english'\n\nprint(f\"\\nIdioma detectado: {idioma_deteccao}\")\n\n# Criar e treinar sistema\nsystem = AeroSulSystem(language=idioma_deteccao)\nsystem.train_from_data(df_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-test-sentiment"
   },
   "source": [
    "## üìä Passo 5: Teste de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-sentiment"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTE 1: Predi√ß√£o de Sentimentos\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 1: PREDI√á√ÉO DE SENTIMENTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "textos_teste = [\n",
    "    \"Flight was amazing great service\",\n",
    "    \"Terrible experience lost my luggage\",\n",
    "    \"Normal flight nothing special\",\n",
    "    \"Best airline ever very happy\",\n",
    "    \"Worst flight of my life delayed 5 hours\",\n",
    "]\n",
    "\n",
    "print(\"\\nüìù Textos de teste:\")\npredictions = system.sentiment_model.predict(textos_teste)\n\nfor texto, pred in zip(textos_teste, predictions):\n    emoji = \"üò¢\" if pred == 'negative' else \"üòä\" if pred == 'positive' else \"üòê\"\n    print(f\"\\n{emoji} Texto: {texto[:50]}...\")\n    print(f\"   Sentimento: {pred.upper()}\")\n\nprint(\"\\n‚úÖ Teste de Sentimentos Conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-test-analysis"
   },
   "source": [
    "## üìà Passo 6: An√°lise Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-analysis"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTE 2: An√°lise Completa\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 2: AN√ÅLISE COMPLETA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar dados de teste\n",
    "df_teste = pd.DataFrame({\n",
    "    'text': [\n",
    "        'lost my luggage terrible',\n",
    "        'amazing experience love it',\n",
    "        'flight delayed nothing special',\n",
    "        'worst customer service ever',\n",
    "        'great airline will book again',\n",
    "    ],\n",
    "    'date': pd.date_range('2024-01-01', periods=5, freq='D')\n",
    "})\n",
    "\nprint(\"\\n[1] Analisando 5 registros...\")\ndf_resultado = system.analyze_data(df_teste.copy(), text_column='text')\nprint(\"‚úì An√°lise conclu√≠da\")\n",
    "\n# Exibir resultados\nprint(\"\\n[2] Resultados da an√°lise:\")\nprint(\"\\n\" + \"-\"*90)\nfor idx, row in df_resultado.iterrows():\n    print(f\"Texto: {row['text'][:30]}\")\n    print(f\"  Sentimento: {row['IA_Sentimento']:10s} | A√ß√£o: {row['Acao_Recomendada'][:45]}\")\n    print()\n\n# Distribui√ß√£o\nprint(\"\\n[3] Distribui√ß√£o de Sentimentos:\")\nfor sent, count in df_resultado['IA_Sentimento'].value_counts().items():\n    barra = \"‚ñà\" * count\n    print(f\"  {sent:10s}: {barra} ({count})\")\n\nprint(\"\\n‚úÖ An√°lise Completa Conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-financial"
   },
   "source": [
    "## üí∞ Passo 7: An√°lise Financeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "financial-analysis"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTE 3: Impacto Financeiro\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 3: IMPACTO FINANCEIRO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar dados com motivos\n",
    "df_financeiro = pd.DataFrame({\n",
    "    'text': ['sample'] * 20,\n",
    "    'IA_Sentimento': ['negative'] * 20,\n",
    "    'IA_Motivo': [\n",
    "        'Lost Luggage', 'Late Flight', 'Cancelled Flight',\n",
    "        'Customer Service Issue', 'Bad Flight'\n",
    "    ] * 4\n",
    "})\n",
    "\nprint(\"\\n[1] Calculando impacto de 20 incidentes...\")\nimpact = system.get_financial_impact(df_financeiro)\n\nprint(\"\\n[2] Resultado Financeiro:\")\nprint(f\"  Total de Incidentes: {impact['total_incidents']}\")\nprint(f\"  Impacto Total (USD): US$ {impact['total_usd']:,.2f}\")\nprint(f\"  Impacto Total (BRL): R$ {impact['total_brl']:,.2f}\")\n\nprint(\"\\n[3] An√°lise por Motivo:\")\nfor motivo, custo in sorted(impact['by_reason'].items(), key=lambda x: x[1], reverse=True):\n    print(f\"  {motivo:30s}: ${custo:>8,.0f}\")\n\nprint(\"\\n‚úÖ An√°lise Financeira Conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-visualizations"
   },
   "source": [
    "## üìä Passo 8: Visualiza√ß√µes (Gr√°ficos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualizations"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configura√ß√£o visual\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZA√á√ïES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar figura com subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribui√ß√£o de Sentimentos (Pizza)\n",
    "sentimentos_conta = df_resultado['IA_Sentimento'].value_counts()\n",
    "cores = {'negative': '#ff6b6b', 'positive': '#51cf66', 'neutral': '#4ecdc4'}\n",
    "cores_list = [cores.get(s, '#999') for s in sentimentos_conta.index]\n",
    "\n",
    "axes[0, 0].pie(sentimentos_conta.values, labels=sentimentos_conta.index, autopct='%1.1f%%',\n",
    "               colors=cores_list, startangle=90)\n",
    "axes[0, 0].set_title('Distribui√ß√£o de Sentimentos', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Distribui√ß√£o de Motivos (Barras)\nif df_resultado['IA_Motivo'].notna().sum() > 0:\n",
    "    motivos_conta = df_resultado[df_resultado['IA_Motivo'] != 'N/A']['IA_Motivo'].value_counts().head(5)\n",
    "    axes[0, 1].barh(motivos_conta.index, motivos_conta.values, color='#ff6b6b')\n",
    "    axes[0, 1].set_title('Top 5 Motivos de Reclama√ß√£o', fontsize=12, fontweight='bold')\n    axes[0, 1].set_xlabel('Frequ√™ncia')\n\n# 3. Impacto Financeiro\nimpact_motivos = sorted(impact['by_reason'].items(), key=lambda x: x[1], reverse=True)[:5]\nif impact_motivos:\n    motivos_fin = [m[0] for m in impact_motivos]\n    valores_fin = [m[1] for m in impact_motivos]\n    axes[1, 0].bar(range(len(motivos_fin)), valores_fin, color='#ffd93d')\n    axes[1, 0].set_xticks(range(len(motivos_fin)))\n    axes[1, 0].set_xticklabels(motivos_fin, rotation=45, ha='right')\n    axes[1, 0].set_title('Top 5 Impacto Financeiro (USD)', fontsize=12, fontweight='bold')\n    axes[1, 0].set_ylabel('Custo (USD)')\n    axes[1, 0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n\n# 4. Resumo Geral (Texto)\naxes[1, 1].axis('off')\nresumo_text = f\"\"\"\nüìä RESUMO GERAL\n\nTotal Analisado: {len(df_resultado)} registros\n\nSentimentos:\n  ‚Ä¢ Negativos: {len(df_resultado[df_resultado['IA_Sentimento'] == 'negative'])} ({len(df_resultado[df_resultado['IA_Sentimento'] == 'negative'])/len(df_resultado)*100:.1f}%)\n  ‚Ä¢ Positivos: {len(df_resultado[df_resultado['IA_Sentimento'] == 'positive'])} ({len(df_resultado[df_resultado['IA_Sentimento'] == 'positive'])/len(df_resultado)*100:.1f}%)\n  ‚Ä¢ Neutros: {len(df_resultado[df_resultado['IA_Sentimento'] == 'neutral'])} ({len(df_resultado[df_resultado['IA_Sentimento'] == 'neutral'])/len(df_resultado)*100:.1f}%)\n\nüí∞ Impacto Financeiro:\n  ‚Ä¢ Total (USD): US$ {impact['total_usd']:,.2f}\n  ‚Ä¢ Total (BRL): R$ {impact['total_brl']:,.2f}\n  ‚Ä¢ Incidentes: {impact['total_incidents']}\n\"\"\"\n\naxes[1, 1].text(0.1, 0.5, resumo_text, fontsize=11, verticalalignment='center',\n                fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n‚úÖ Visualiza√ß√µes geradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-crisis-detection"
   },
   "source": [
    "## ‚ö†Ô∏è Passo 9: Detec√ß√£o de Crises (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crisis-detection"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTE 4: Detec√ß√£o de Crises\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 4: DETEC√á√ÉO DE CRISES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Criar dados temporais com pico de crise\n",
    "dates = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "base_negatives = np.random.randint(5, 15, 30)\n",
    "base_negatives[10:12] = 50  # Pico de crise\n",
    "\n",
    "# Criar dados\ntextos = []\n",
    "sentimentos = []\n",
    "datas_list = []\n",
    "\n",
    "for date, count in zip(dates, base_negatives):\n",
    "    for _ in range(count):\n",
    "        sentimentos.append('negative')\n",
    "        datas_list.append(date)\n",
    "    for _ in range(20 - count):\n",
    "        sentimentos.append('positive')\n",
    "        datas_list.append(date)\n",
    "    textos.extend(['sample'] * 20)\n",
    "\ndf_temp = pd.DataFrame({\n",
    "    'text': textos,\n",
    "    'tweet_created': datas_list,\n",
    "    'IA_Sentimento': sentimentos\n",
    "})\n",
    "\nprint(f\"\\n[1] Analisando dados temporais (30 dias)...\")\nprint(f\"    Total de textos: {len(df_temp)}\")\n\n# Detectar crise\nprint(f\"\\n[2] Detectando crises...\")\ncrisis = system.detect_crisis(df_temp, date_column='tweet_created')\n\nprint(f\"\\n[3] Resultado:\")\nif crisis.get('is_crisis'):\n    print(f\"    ‚ö†Ô∏è  CRISE DETECTADA!\")\n    print(f\"    Data cr√≠tica: {crisis['max_date']}\")\n    print(f\"    Reclama√ß√µes no pico: {crisis['max_count']}\")\n    print(f\"    Limiar normal: {crisis['normal_mean']:.1f} reclama√ß√µes/dia\")\n    print(f\"    Limiar de crise: {crisis['threshold']:.1f} reclama√ß√µes/dia\")\n    print(f\"    Fator de severidade: {crisis['severity_factor']:.2f}x acima do normal\")\nelse:\n    print(f\"    ‚úì Nenhuma crise detectada\")\n    print(f\"    Limiar normal: {crisis.get('normal_mean', 'N/A')}\")\n\nprint(\"\\n‚úÖ An√°lise de Crise Conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-export"
   },
   "source": [
    "## üì• Passo 10: Download de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-results"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SALVAR RESULTADOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì• SALVANDO RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Salvar resultado an√°lise\narquivo_resultado = '/content/resultado_analise.xlsx'\ndf_resultado.to_excel(arquivo_resultado, index=False)\nprint(f\"\\n‚úì Resultado da an√°lise: {arquivo_resultado}\")\n\n# Criar resumo JSON\nresumo = {\n    'timestamp': datetime.now().isoformat(),\n    'total_analisados': len(df_resultado),\n    'sentimentos': df_resultado['IA_Sentimento'].value_counts().to_dict(),\n    'motivos': df_resultado['IA_Motivo'].value_counts().to_dict(),\n    'impacto_financeiro': {\n        'total_usd': float(impact['total_usd']),\n        'total_brl': float(impact['total_brl']),\n        'incidentes': impact['total_incidents']\n    }\n}\n\nimport json\narquivo_resumo = '/content/resumo.json'\nwith open(arquivo_resumo, 'w') as f:\n    json.dump(resumo, f, indent=2)\nprint(f\"‚úì Resumo dos resultados: {arquivo_resumo}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéâ SISTEMA EXECUTADO COM SUCESSO!\")\nprint(\"=\"*70)\n\nprint(\"\\nüìä Estat√≠sticas Finais:\")\nprint(f\"\\n  Total de registros analisados: {len(df_resultado)}\")\nprint(f\"\\n  Distribui√ß√£o de Sentimentos:\")\nfor sent, count in df_resultado['IA_Sentimento'].value_counts().items():\n    pct = count/len(df_resultado)*100\n    print(f\"    ‚Ä¢ {sent:10s}: {count:3d} ({pct:5.1f}%)\")\n\nprint(f\"\\n  Impacto Financeiro:\")\nprint(f\"    ‚Ä¢ Total (USD): US$ {impact['total_usd']:,.2f}\")\nprint(f\"    ‚Ä¢ Total (BRL): R$ {impact['total_brl']:,.2f}\")\nprint(f\"    ‚Ä¢ Incidentes: {impact['total_incidents']}\")\n\nprint(f\"\\n‚úÖ Arquivos salvos e prontos para download!\")\nprint(f\"   Use o menu √† esquerda para baixar os arquivos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell-notes"
   },
   "source": [
    "## üìù Notas e Pr√≥ximos Passos\n",
    "\n",
    "### ‚úÖ O que foi feito:\n",
    "1. ‚úì Instalou depend√™ncias Python\n",
    "2. ‚úì Carregou o sistema inteligente AeroSul\n",
    "3. ‚úì Treinou modelos de ML\n",
    "4. ‚úì Testou classifica√ß√£o de sentimentos\n",
    "5. ‚úì Realizou an√°lise completa\n",
    "6. ‚úì Calculou impacto financeiro\n",
    "7. ‚úì Gerou visualiza√ß√µes\n",
    "8. ‚úì Detectou crises (opcional)\n",
    "9. ‚úì Salvou resultados\n",
    "\n",
    "### üìä Dados Dispon√≠veis:\n",
    "- **resultado_analise.xlsx** - Resultado detalhado da an√°lise\n",
    "- **resumo.json** - Resumo em formato JSON\n",
    "\n",
    "### üîÑ Pr√≥ximos Passos:\n",
    "1. **Fazer upload de seu arquivo real** - Volte ao Passo 4 e fa√ßa upload de seu arquivo\n",
    "2. **Analisar seus dados** - O sistema analisar√° seus dados pr√≥prios\n",
    "3. **Exportar resultados** - Baixe os arquivos gerados\n",
    "4. **Integrar em produ√ß√£o** - Use os c√≥digo nos ambientes de produ√ß√£o\n",
    "\n",
    "### üìö Documenta√ß√£o Completa:\n",
    "- Veja os arquivos .md no reposit√≥rio original para mais informa√ß√µes\n",
    "- README.md - Documenta√ß√£o t√©cnica\n",
    "- QUICKSTART.md - Guia r√°pido\n",
    "- AMBIENTES_EXECUCAO.md - Onde rodar o sistema\n",
    "\n",
    "### üí° Dicas:\n",
    "- Para usar seu pr√≥prio arquivo, volte ao Passo 4 e fa√ßa upload\n",
    "- O sistema detecta automaticamente se √© Excel ou CSV\n",
    "- Maior dataset = melhor acur√°cia (m√≠nimo 500 registros recomendado)\n",
    "- Execute **Runtime** ‚Üí **Run all** para re-executar tudo\n",
    "\n",
    "---\n",
    "\n",
    "**Status:** ‚úÖ Sistema Inteligente AeroSul pronto para uso!\n",
    "\n",
    "**Vers√£o:** 1.0.0\n",
    "\n",
    "**Data:** Dezembro 2024"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
